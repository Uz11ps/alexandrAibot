"""–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å AI (OpenAI)"""
import logging
import asyncio
import re
from typing import Optional, List, Dict
from openai import AsyncOpenAI
from openai import RateLimitError, APIError
import httpx
from config.settings import settings

logger = logging.getLogger(__name__)


def clean_ai_response(text: str) -> str:
    """
    –û—á–∏—â–∞–µ—Ç –æ—Ç–≤–µ—Ç AI –æ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
    """
    if not text:
        return ""
        
    # –£–¥–∞–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏-—á–µ—Ä–Ω–æ–≤–∏–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–æ—Å–æ—á–∏–ª–∏—Å—å
    text = re.sub(r'üìù –ß–µ—Ä–Ω–æ–≤–∏–∫ –ø–æ—Å—Ç–∞ –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è:?\s*', '', text, flags=re.IGNORECASE)
    
    # –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ –≤–∏–¥—ã –¥–ª–∏–Ω–Ω—ã—Ö –∏ —Å—Ä–µ–¥–Ω–∏—Ö —Ç–∏—Ä–µ –Ω–∞ –æ–±—ã—á–Ω—ã–π –¥–µ—Ñ–∏—Å –ø–æ –ø—Ä–æ—Å—å–±–µ –∑–∞–∫–∞–∑—á–∏–∫–∞
    text = text.replace(' ‚Äî ', ' - ')
    text = text.replace(' ‚Äì ', ' - ')
    text = text.replace('‚Äî', '-')
    text = text.replace('‚Äì', '-')
    
    # –£–¥–∞–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—á–∞–Ω–∏—è AI
    lines = text.split('\n')
    cleaned_lines = []
    skip_rest = False
    
    for line in lines:
        if line.strip().startswith('---'):
            skip_rest = True
            break
        if '–≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç' in line or '—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º' in line:
            skip_rest = True
            break
        if skip_rest:
            continue
        cleaned_lines.append(line)
    
    cleaned_text = '\n'.join(cleaned_lines).strip()
    
    # –£–¥–∞–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –º—É—Å–æ—Ä –≤ –∫–æ–Ω—Ü–µ
    patterns_to_remove = [
        r'---.*$',
        r'–≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç.*$',
        r'—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º.*$',
        r'–¥–µ–ª–∞—è –µ–≥–æ –≤–∏–∑—É–∞–ª—å–Ω–æ.*$',
        r'–ª–µ–≥–∫–∏–º –¥–ª—è –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è.*$'
    ]
    
    for pattern in patterns_to_remove:
        cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.MULTILINE | re.IGNORECASE)
    
    return cleaned_text.strip()


def markdown_to_html(text: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ HTML –¥–ª—è Telegram
    """
    if not text:
        return ""
    # –ó–∞–º–µ–Ω—è–µ–º **—Ç–µ–∫—Å—Ç** –Ω–∞ <b>—Ç–µ–∫—Å—Ç</b>
    text = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', text)
    # –ó–∞–º–µ–Ω—è–µ–º *—Ç–µ–∫—Å—Ç* –Ω–∞ <i>—Ç–µ–∫—Å—Ç</i>
    text = re.sub(r'(?<!\*)\*([^*\n]+?)\*(?!\*)', r'<i>\1</i>', text)
    # –ó–∞–º–µ–Ω—è–µ–º `—Ç–µ–∫—Å—Ç` –Ω–∞ <code>—Ç–µ–∫—Å—Ç</code>
    text = re.sub(r'`([^`]+?)`', r'<code>\1</code>', text)
    # –ó–∞–º–µ–Ω—è–µ–º [—Ç–µ–∫—Å—Ç](url) –Ω–∞ <a href="url">—Ç–µ–∫—Å—Ç</a>
    text = re.sub(r'\[([^\]]+?)\]\((https?://[^\)]+?)\)', r'<a href="\2">\1</a>', text)
    return text


class AIService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å OpenAI API"""
    
    def __init__(self, prompt_config_service=None):
        self.prompt_config_service = prompt_config_service
        self.proxy_list = []
        self.current_proxy_index = 0
        self.current_api_key_index = 0
        
        # –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–π
        self.api_keys = [settings.OPENAI_API_KEY]
        if settings.OPENAI_API_KEYS:
            additional_keys = [k.strip() for k in settings.OPENAI_API_KEYS.split(',')]
            self.api_keys.extend(additional_keys)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∫—Å–∏
        http_client = None
        if settings.OPENAI_PROXY_ENABLED and settings.OPENAI_PROXY_URL:
            proxy_urls = [p.strip() for p in settings.OPENAI_PROXY_URL.split(',')]
            normalized_proxies = []
            for proxy in proxy_urls:
                if proxy.count(':') == 3 and not proxy.startswith('http'):
                    parts = proxy.split(':')
                    normalized_proxies.append(f"http://{parts[2]}:{parts[3]}@{parts[0]}:{parts[1]}")
                else:
                    normalized_proxies.append(proxy)
            self.proxy_list = normalized_proxies
            
            http_client = httpx.AsyncClient(
                proxy=self.proxy_list[0],
                timeout=httpx.Timeout(300.0, connect=60.0, read=300.0)
            )
        
        self.client = AsyncOpenAI(api_key=self.api_keys[0], http_client=http_client)
        self.model = settings.OPENAI_MODEL
        self.proxy_enabled = settings.OPENAI_PROXY_ENABLED
        
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ temperature
        self.supports_temperature = not (self.model.startswith("gpt-5") or "o1" in self.model.lower())
    
    def _switch_proxy(self):
        if len(self.proxy_list) > 1:
            self.current_proxy_index = (self.current_proxy_index + 1) % len(self.proxy_list)
            logger.info(f"–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ–∫—Å–∏ #{self.current_proxy_index + 1}")
            http_client = httpx.AsyncClient(
                proxy=self.proxy_list[self.current_proxy_index],
                timeout=httpx.Timeout(300.0, connect=60.0, read=300.0)
            )
            self.client = AsyncOpenAI(api_key=self.api_keys[self.current_api_key_index], http_client=http_client)
            return True
        return False
    
    def _switch_api_key(self):
        if len(self.api_keys) > 1:
            self.current_api_key_index = (self.current_api_key_index + 1) % len(self.api_keys)
            logger.info(f"–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ API –∫–ª—é—á #{self.current_api_key_index + 1}")
            self.client = AsyncOpenAI(api_key=self.api_keys[self.current_api_key_index])
            return True
        return False
    
    async def generate_post_text(self, prompt: str, context: Optional[str] = None, photos_description: Optional[str] = None, prompt_key: str = "generate_post") -> str:
        if self.prompt_config_service:
            system_prompt = self.prompt_config_service.get_prompt(prompt_key, "system_prompt") or self._get_default_system_prompt()
        else:
            system_prompt = self._get_default_system_prompt()
        
        user_msg = f"–ò–ù–°–¢–†–£–ö–¶–ò–Ø:\n{system_prompt}\n\n–ó–ê–î–ê–ù–ò–ï:\n{prompt}"
        if context: user_msg += f"\n\n–ö–û–ù–¢–ï–ö–°–¢:\n{context}"
        if photos_description: user_msg += f"\n\n–û–ü–ò–°–ê–ù–ò–ï –ú–ï–î–ò–ê:\n{photos_description}"
        
        try:
            params = {
                "model": self.model,
                "messages": [{"role": "user", "content": user_msg}],
                "max_completion_tokens": 8000
            }
            if self.supports_temperature: params["temperature"] = 0.7
            
            response = await asyncio.wait_for(self.client.chat.completions.create(**params), timeout=180.0)
            result = response.choices[0].message.content.strip()
            return markdown_to_html(clean_ai_response(result))
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ {self.model}: {e}. –ü—Ä–æ–±—É—é —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª—å gpt-4o...")
            try:
                # –†–µ–∑–µ—Ä–≤–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–∞ gpt-4o
                response = await self.client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": user_msg}],
                    max_tokens=4000,
                    temperature=0.7
                )
                result = response.choices[0].message.content.strip()
                return markdown_to_html(clean_ai_response(result))
            except Exception as e2:
                logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–∞–∂–µ –Ω–∞ gpt-4o: {e2}")
                return "üìä <b>–ù–æ–≤–æ—Å—Ç–∏ –ê—Ä—Ö–ò–æ–Ω</b>\n\n–°–ª–µ–¥–∏–º –∑–∞ —Ä—ã–Ω–∫–æ–º –ò–ñ–°. –°–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è!"
    
    async def analyze_photo(self, photo_path: str) -> str:
        import base64
        from PIL import Image
        import io
        try:
            with Image.open(photo_path) as img:
                if img.mode != 'RGB': img = img.convert('RGB')
                img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
                buf = io.BytesIO()
                img.save(buf, format='JPEG', quality=85)
                image_data = buf.getvalue()
        except Exception:
            with open(photo_path, "rb") as f: image_data = f.read()
            
        b64 = base64.b64encode(image_data).decode('utf-8')
        prompt = self._get_photo_analysis_prompt()
        
        try:
            response = await asyncio.wait_for(
                self.client.chat.completions.create(
                    model="gpt-5.2",
                    messages=[{
            "role": "user",
            "content": [
                            {"type": "text", "text": f"–ò–ù–°–¢–†–£–ö–¶–ò–Ø: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–æ—Ç–æ –∫–∞–∫ —Ç–µ—Ö–Ω–∞–¥–∑–æ—Ä –ê—Ä—Ö–ò–æ–Ω.\n–ó–ê–î–ê–ù–ò–ï: {prompt}"},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}}
                        ]
                    }],
                    max_completion_tokens=4000
                ),
                timeout=180.0
            )
            return response.choices[0].message.content.strip() or "–°—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –ê—Ä—Ö–ò–æ–Ω."
        except Exception:
            return "–û–±—ä–µ–∫—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –ê—Ä—Ö–ò–æ–Ω."

    async def analyze_multiple_photos(self, photo_paths: List[str]) -> str:
        descs = []
        for i, p in enumerate(photo_paths[:5], 1):
            d = await self.analyze_photo(p)
            descs.append(f"–§–æ—Ç–æ {i}: {d}")
        return "\n\n".join(descs)
    
    async def generate_post_from_sources(self, source_posts: List[Dict[str, str]], topic: Optional[str] = None) -> str:
        if not source_posts: return self._get_fallback_source_post()
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ò–ò, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–≤—è–∑—å —Ç–µ–∫—Å—Ç–∞ –∏ —Å—Å—ã–ª–∫–∏
        context_items = []
        for i, p in enumerate(source_posts[:15], 1): # –ë–µ—Ä–µ–º –¥–æ 15 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã
            text = p.get('text', '')
            source_url = p.get('source', '–ë–µ–∑ —Å—Å—ã–ª–∫–∏')
            if text:
                context_items.append(f"–ù–û–í–û–°–¢–¨ ‚Ññ{i}:\n–¢–ï–ö–°–¢: {text}\n–ò–°–¢–û–ß–ù–ò–ö: {source_url}")
            
        context = "\n\n---\n\n".join(context_items)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π
        if self.prompt_config_service:
            sys_prompt = self.prompt_config_service.get_prompt("generate_from_sources", "system_prompt")
        else:
            sys_prompt = None

        if not sys_prompt:
            sys_prompt = """–¢—ã ‚Äì —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–µ–ª–æ–≤–æ–≥–æ –°–ú–ò, –∫–æ—Ç–æ—Ä—ã–π –ø–∏—à–µ—Ç –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —á–∏—Ç–∞—Ç–µ–ª–µ–π, –∞ –Ω–µ –¥–ª—è –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤. –¢–µ–±–µ –ø–µ—Ä–µ–¥–∞–Ω —Ç–µ–∫—Å—Ç –æ —Ä—ã–Ω–∫–µ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏, –∏–ø–æ—Ç–µ–∫–µ –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–µ, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–π –∫–∞–Ω—Ü–µ–ª—è—Ä—Å–∫–∏–º –∏ —Ç–µ—Ö–Ω–æ–∫—Ä–∞—Ç–∏—á–µ—Å–∫–∏–º —è–∑—ã–∫–æ–º. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äì –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –µ–≥–æ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω —Å—á–∏—Ç–∞–ª—Å—è –∫–∞–∫ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç—Å–∫–∞—è —Å—Ç–∞—Ç—å—è –¥–ª—è —à–∏—Ä–æ–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –ù–ò–ö–ê–ö–û–ì–û –û–§–ò–¶–ò–û–ó–ê: –ó–∞–º–µ–Ω—è–π —Ñ—Ä–∞–∑—ã –≤—Ä–æ–¥–µ ¬´—Å–º–µ—â–µ–Ω–∏–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–π¬ª, ¬´–æ—Ö–ª–∞–∂–¥–µ–Ω–∏–µ –∏–ø–æ—Ç–µ–∫–∏¬ª –Ω–∞ –∂–∏–≤—ã–µ, –ø–æ–Ω—è—Ç–Ω—ã–µ —á–µ–ª–æ–≤–µ–∫—É —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏.
2. –ü–ò–®–ò –û–¢ –ü–ï–†–í–û–ì–û –õ–ò–¶–ê: –ò—Å–ø–æ–ª—å–∑—É–π ¬´–º—ã –≤ –ê—Ä—Ö–ò–æ–Ω–µ¬ª, ¬´–Ω–∞ –Ω–∞—à–∏—Ö –æ–±—ä–µ–∫—Ç–∞—Ö¬ª, ¬´–º—ã –≤–∏–¥–∏–º¬ª. 
3. –û–ë–™–Ø–°–ù–Ø–ô –¢–ï–†–ú–ò–ù–´: –ï—Å–ª–∏ –Ω—É–∂–µ–Ω —Ç–µ—Ä–º–∏–Ω (—ç—Å–∫—Ä–æ—É, –ì—Ä–∞–¥–ø–ª–∞–Ω), –æ–±—ä—è—Å–Ω–∏ –µ–≥–æ –ø—Ä–æ—Å—Ç–æ –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞.
4. –õ–û–ì–ò–ö–ê –í–´–ë–û–†–ê: –î–µ–ª–∞–π –∞–∫—Ü–µ–Ω—Ç –Ω–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π –ª–æ–≥–∏–∫–µ (–¥–µ–Ω—å–≥–∏, –º–µ—Ç—Ä—ã, –∫–æ–º—Ñ–æ—Ä—Ç, —Ç–∏—à–∏–Ω–∞).
5. –ò–ó–ë–ï–ì–ê–ô –ü–†–û–ì–ù–û–ó–û–í-–û–¢–ß–ï–¢–û–í: –í–º–µ—Å—Ç–æ ¬´–≤ 2025 –¥–æ–ª—è –∑–∞–∫—Ä–µ–ø–∏—Ç—Å—è¬ª –ø–∏—à–∏ ¬´–º—ã —É–∂–µ –≤–∏–¥–∏–º –ø–æ –Ω–∞—à–∏–º –∑–∞—è–≤–∫–∞–º¬ª.
6. –¢–ò–ü–û–ì–†–ê–§–ò–ö–ê: –¢–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–∏–µ –¥–µ—Ñ–∏—Å—ã (-). –î–ª–∏–Ω–Ω—ã–µ —Ç–∏—Ä–µ (‚Äî) –∑–∞–ø—Ä–µ—â–µ–Ω—ã.

–°—Ç—Ä—É–∫—Ç—É—Ä–∞:
- –ó–∞–≥–æ–ª–æ–≤–æ–∫ (–±–µ–∑ —Å–ª–æ–≤–∞ "–î–∞–π–¥–∂–µ—Å—Ç")
- 3-4 –∫–æ—Ä–æ—Ç–∫–∏—Ö –±–ª–æ–∫–∞ —Å –ø–æ–ª—å–∑–æ–π
- –ò—Ç–æ–≥: —á—Ç–æ –¥–µ–ª–∞—Ç—å –∫–ª–∏–µ–Ω—Ç—É –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å."""

        topic_str = f"–ü–†–ò–û–†–ò–¢–ï–¢–ù–ê–Ø –¢–ï–ú–ê: {topic}\n" if topic else ""
        user_msg = f"{topic_str}–î–ê–ù–ù–´–ï –ò–ó –ò–°–¢–û–ß–ù–ò–ö–û–í:\n{context}\n\n–ó–ê–î–ê–ù–ò–ï: –ù–∞–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π –ø–æ—Å—Ç –≤ —Å—Ç–∏–ª–µ –¥–µ–ª–æ–≤–æ–≥–æ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç–∞. –ï—Å–ª–∏ —Ç–µ–º–∞ —É–∫–∞–∑–∞–Ω–∞ –≤—ã—à–µ ‚Äî —Å—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –Ω–µ–π –Ω–∞ 80%."
        
        try:
            params = {
                "model": self.model,
                "messages": [{"role": "user", "content": f"–ò–ù–°–¢–†–£–ö–¶–ò–Ø:\n{sys_prompt}\n\n–ó–ê–î–ê–ù–ò–ï:\n{user_msg}"}],
                "max_completion_tokens": 5000
            }
            if self.supports_temperature: params["temperature"] = 0.7
            
            response = await asyncio.wait_for(self.client.chat.completions.create(**params), timeout=180.0)
            res = response.choices[0].message.content.strip()
            
            # –û—á–∏—â–∞–µ–º –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
            cleaned = clean_ai_response(res)
            return markdown_to_html(cleaned)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º: {e}")
            # –§–æ–ª–±—ç–∫ —Å —Å—ã—Ä—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏ –µ—Å–ª–∏ –ò–ò –ø–æ–¥–≤–µ–ª
            links = "\n".join([f"‚Ä¢ {p.get('source')}" for p in source_posts[:5] if p.get('source')])
            return f"üìä <b>–ù–æ–≤–æ—Å—Ç–∏ –ò–ñ–° –ö—Ä—ã–º</b>\n\n–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ —Å —Ä—ã–Ω–∫–∞. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã: –∑–∞–∫–æ–Ω –æ–± –ò–ñ–° –∏ –Ω–æ–≤—ã–µ –∏–ø–æ—Ç–µ—á–Ω—ã–µ —Å—Ç–∞–≤–∫–∏.\n\nüîó <b>–ò—Å—Ç–æ—á–Ω–∏–∫–∏:</b>\n{links}"
    
    async def refine_post(self, original_post: str, edits: str) -> str:
        sys_prompt = "–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –ê—Ä—Ö–ò–æ–Ω. –ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–π —Ç–µ–∫—Å—Ç —Å —É—á–µ—Ç–æ–º –ø—Ä–∞–≤–æ–∫, —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –æ–±—ä–µ–º 1500-2000 —Å–∏–º–≤."
        user_msg = f"–¢–ï–ö–°–¢:\n{original_post}\n\n–ü–†–ê–í–ö–ò:\n{edits}"
        try:
            response = await self.client.chat.completions.create(
                    model=self.model,
                messages=[{"role": "user", "content": f"–ò–ù–°–¢–†–£–ö–¶–ò–Ø:\n{sys_prompt}\n\n–ó–ê–î–ê–ù–ò–ï:\n{user_msg}"}],
                max_completion_tokens=5000
            )
            return markdown_to_html(clean_ai_response(response.choices[0].message.content.strip()))
        except Exception:
            return original_post

    def _get_default_system_prompt(self) -> str:
        return """–¢—ã ‚Äì —Ä–µ–¥–∞–∫—Ç–æ—Ä –¥–µ–ª–æ–≤–æ–≥–æ –°–ú–ò, –ø–∏—à—É—â–∏–π –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –ª—é–¥–µ–π –æ—Ç –ª–∏—Ü–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –ê—Ä—Ö–ò–æ–Ω. 

–ü–†–ê–í–ò–õ–ê –ì–û–õ–û–°–ê:
1. –ü–∏—à–∏ –ø—Ä–æ—Å—Ç–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ, –∫–∞–∫ –±—É–¥—Ç–æ –æ–±—ä—è—Å–Ω—è–µ—à—å –¥—Ä—É–≥—É. –£–±–∏—Ä–∞–π –∫–∞–Ω—Ü–µ–ª—è—Ä—Å–∫–∏–π —è–∑—ã–∫.
2. –ò—Å–ø–æ–ª—å–∑—É–π ¬´–º—ã –≤ –ê—Ä—Ö–ò–æ–Ω–µ¬ª, ¬´–Ω–∞ –Ω–∞—à–∏—Ö –æ–±—ä–µ–∫—Ç–∞—Ö¬ª.
3. –¢–ï–†–ú–ò–ù–´: –í–º–µ—Å—Ç–æ "—Å—Ç—Ä–æ–π–∫–∞ –¥–æ–º–∞" –ø–∏—à–∏ "—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ –¥–æ–º–∞". –ì–ü–ó–£ ‚Äî —ç—Ç–æ –ì—Ä–∞–¥–ø–ª–∞–Ω.
4. –≠–°–ö–†–û–£: –≠—Ç–æ –¥–µ–Ω—å–≥–∏ –≤ –±–∞–Ω–∫–µ –¥–æ –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–æ–π–∫–∏.
5. –ó–ê–ü–†–ï–¢ –ñ–ê–†–ì–û–ù–ê: "–∫–ª–∏–µ–Ω—Ç–æ—Ü–µ–Ω—Ç—Ä–∏—á–Ω–æ—Å—Ç—å", "–∫–µ–π—Å", "–ª–∏–¥", "SLA".
6. –¢–ò–ü–û–ì–†–ê–§–ò–ö–ê: –¢–æ–ª—å–∫–æ –æ–±—ã—á–Ω—ã–µ –¥–µ—Ñ–∏—Å—ã (-)."""

    def _get_photo_analysis_prompt(self) -> str:
        return "–û–ø–∏—à–∏ —ç—Ç–∞–ø —Ä–∞–±–æ—Ç, –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –∫–∞—á–µ—Å—Ç–≤–æ –∏ –¥–µ—Ç–∞–ª–∏ –Ω–∞ —Ñ–æ—Ç–æ –∫–∞–∫ –∏–Ω–∂–µ–Ω–µ—Ä —Ç–µ—Ö–Ω–∞–¥–∑–æ—Ä–∞."
    
    def _get_fallback_source_post(self) -> str:
        return "üèóÔ∏è <b>–ù–æ–≤–æ—Å—Ç–∏ –ê—Ä—Ö–ò–æ–Ω</b>\n\n–°–ª–µ–¥–∏–º –∑–∞ —Ä—ã–Ω–∫–æ–º –ò–ñ–° –ö—Ä—ã–º–∞. –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤ —Å–ª–µ–¥—É—é—â–∏—Ö –≤—ã–ø—É—Å–∫–∞—Ö!"

    async def make_news_standalone(self, text: str) -> str:
        return await self.refine_post(text, "–°–¥–µ–ª–∞–π –Ω–æ–≤–æ—Å—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π, —É–±–µ—Ä–∏ –æ—Ç—Å—ã–ª–∫–∏ –∫ –ø—Ä–æ—à–ª–æ–º—É.")
        
    async def analyze_video(self, video_path: str) -> str:
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —á–µ—Ä–µ–∑ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ (–Ω—É–∂–µ–Ω cv2)
        try:
            import cv2
            cap = cv2.VideoCapture(video_path)
            total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            descs = []
            for i in range(3): # –ë–µ—Ä–µ–º 3 –∫–∞–¥—Ä–∞
                cap.set(cv2.CAP_PROP_POS_FRAMES, (total // 4) * (i + 1))
                ret, frame = cap.read()
                if ret:
                    cv2.imwrite("temp_frame.jpg", frame)
                    d = await self.analyze_photo("temp_frame.jpg")
                    descs.append(d)
            cap.release()
            return "–ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ: " + " ".join(descs)
        except Exception:
            return "–í–∏–¥–µ–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –ê—Ä—Ö–ò–æ–Ω."
