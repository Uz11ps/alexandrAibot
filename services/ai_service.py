"""–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å AI (OpenAI)"""
import logging
import asyncio
import re
from typing import Optional, List, Dict
from openai import AsyncOpenAI
from openai import RateLimitError, APIError
import httpx
from config.settings import settings

logger = logging.getLogger(__name__)


def clean_ai_response(text: str) -> str:
    """
    –û—á–∏—â–∞–µ—Ç –æ—Ç–≤–µ—Ç AI –æ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
    """
    if not text:
        return ""
        
    # –£–¥–∞–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏-—á–µ—Ä–Ω–æ–≤–∏–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–æ—Å–æ—á–∏–ª–∏—Å—å
    text = re.sub(r'üìù –ß–µ—Ä–Ω–æ–≤–∏–∫ –ø–æ—Å—Ç–∞ –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è:?\s*', '', text, flags=re.IGNORECASE)
    
    # –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ –≤–∏–¥—ã –¥–ª–∏–Ω–Ω—ã—Ö –∏ —Å—Ä–µ–¥–Ω–∏—Ö —Ç–∏—Ä–µ –Ω–∞ –æ–±—ã—á–Ω—ã–π –¥–µ—Ñ–∏—Å –ø–æ –ø—Ä–æ—Å—å–±–µ –∑–∞–∫–∞–∑—á–∏–∫–∞
    text = text.replace(' ‚Äî ', ' - ')
    text = text.replace(' ‚Äì ', ' - ')
    text = text.replace('‚Äî', '-')
    text = text.replace('‚Äì', '-')
    
    # –£–¥–∞–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—á–∞–Ω–∏—è AI
    lines = text.split('\n')
    cleaned_lines = []
    skip_rest = False
    
    for line in lines:
        if line.strip().startswith('---'):
            skip_rest = True
            break
        if '–≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç' in line or '—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º' in line:
            skip_rest = True
            break
        if skip_rest:
            continue
        cleaned_lines.append(line)
    
    cleaned_text = '\n'.join(cleaned_lines).strip()
    
    # –£–¥–∞–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –º—É—Å–æ—Ä –≤ –∫–æ–Ω—Ü–µ
    patterns_to_remove = [
        r'---.*$',
        r'–≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç.*$',
        r'—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º.*$',
        r'–¥–µ–ª–∞—è –µ–≥–æ –≤–∏–∑—É–∞–ª—å–Ω–æ.*$',
        r'–ª–µ–≥–∫–∏–º –¥–ª—è –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è.*$'
    ]
    
    for pattern in patterns_to_remove:
        cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.MULTILINE | re.IGNORECASE)
    
    return cleaned_text.strip()


def markdown_to_html(text: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ HTML –¥–ª—è Telegram
    """
    if not text:
        return ""
    # –ó–∞–º–µ–Ω—è–µ–º **—Ç–µ–∫—Å—Ç** –Ω–∞ <b>—Ç–µ–∫—Å—Ç</b>
    text = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', text)
    # –ó–∞–º–µ–Ω—è–µ–º *—Ç–µ–∫—Å—Ç* –Ω–∞ <i>—Ç–µ–∫—Å—Ç</i>
    text = re.sub(r'(?<!\*)\*([^*\n]+?)\*(?!\*)', r'<i>\1</i>', text)
    # –ó–∞–º–µ–Ω—è–µ–º `—Ç–µ–∫—Å—Ç` –Ω–∞ <code>—Ç–µ–∫—Å—Ç</code>
    text = re.sub(r'`([^`]+?)`', r'<code>\1</code>', text)
    # –ó–∞–º–µ–Ω—è–µ–º [—Ç–µ–∫—Å—Ç](url) –Ω–∞ <a href="url">—Ç–µ–∫—Å—Ç</a>
    text = re.sub(r'\[([^\]]+?)\]\((https?://[^\)]+?)\)', r'<a href="\2">\1</a>', text)
    return text


class AIService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å OpenAI API"""
    
    def __init__(self, prompt_config_service=None):
        self.prompt_config_service = prompt_config_service
        self.proxy_list = []
        self.current_proxy_index = 0
        self.current_api_key_index = 0
        
        # –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–π
        self.api_keys = [settings.OPENAI_API_KEY]
        if settings.OPENAI_API_KEYS:
            additional_keys = [k.strip() for k in settings.OPENAI_API_KEYS.split(',')]
            self.api_keys.extend(additional_keys)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∫—Å–∏
        http_client = None
        if settings.OPENAI_PROXY_ENABLED and settings.OPENAI_PROXY_URL:
            proxy_urls = [p.strip() for p in settings.OPENAI_PROXY_URL.split(',')]
            normalized_proxies = []
            for proxy in proxy_urls:
                if proxy.count(':') == 3 and not proxy.startswith('http'):
                    parts = proxy.split(':')
                    normalized_proxies.append(f"http://{parts[2]}:{parts[3]}@{parts[0]}:{parts[1]}")
                else:
                normalized_proxies.append(proxy)
            self.proxy_list = normalized_proxies
            
            http_client = httpx.AsyncClient(
                proxy=self.proxy_list[0],
                timeout=httpx.Timeout(300.0, connect=60.0, read=300.0)
            )
        
        self.client = AsyncOpenAI(api_key=self.api_keys[0], http_client=http_client)
        self.model = settings.OPENAI_MODEL
        self.proxy_enabled = settings.OPENAI_PROXY_ENABLED
        
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ temperature
        self.supports_temperature = not (self.model.startswith("gpt-5") or "o1" in self.model.lower())
    
    def _switch_proxy(self):
        if len(self.proxy_list) > 1:
            self.current_proxy_index = (self.current_proxy_index + 1) % len(self.proxy_list)
            logger.info(f"–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ–∫—Å–∏ #{self.current_proxy_index + 1}")
            http_client = httpx.AsyncClient(
                proxy=self.proxy_list[self.current_proxy_index],
                timeout=httpx.Timeout(300.0, connect=60.0, read=300.0)
            )
            self.client = AsyncOpenAI(api_key=self.api_keys[self.current_api_key_index], http_client=http_client)
            return True
        return False
    
    def _switch_api_key(self):
        if len(self.api_keys) > 1:
            self.current_api_key_index = (self.current_api_key_index + 1) % len(self.api_keys)
            logger.info(f"–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ API –∫–ª—é—á #{self.current_api_key_index + 1}")
            self.client = AsyncOpenAI(api_key=self.api_keys[self.current_api_key_index])
            return True
        return False
    
    async def generate_post_text(self, prompt: str, context: Optional[str] = None, photos_description: Optional[str] = None) -> str:
        if self.prompt_config_service:
            system_prompt = self.prompt_config_service.get_prompt("generate_post", "system_prompt") or self._get_default_system_prompt()
        else:
            system_prompt = self._get_default_system_prompt()
        
        user_msg = f"–ò–ù–°–¢–†–£–ö–¶–ò–Ø:\n{system_prompt}\n\n–ó–ê–î–ê–ù–ò–ï:\n{prompt}"
        if context: user_msg += f"\n\n–ö–û–ù–¢–ï–ö–°–¢:\n{context}"
        if photos_description: user_msg += f"\n\n–û–ü–ò–°–ê–ù–ò–ï –ú–ï–î–ò–ê:\n{photos_description}"
        
        try:
            params = {
                "model": self.model,
                "messages": [{"role": "user", "content": user_msg}],
                "max_completion_tokens": 8000
            }
            if self.supports_temperature: params["temperature"] = 0.7
            
            response = await asyncio.wait_for(self.client.chat.completions.create(**params), timeout=180.0)
            result = response.choices[0].message.content.strip()
            return markdown_to_html(clean_ai_response(result))
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ {self.model}: {e}. –ü—Ä–æ–±—É—é —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª—å gpt-4o...")
            try:
                # –†–µ–∑–µ—Ä–≤–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–∞ gpt-4o
                response = await self.client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": user_msg}],
                    max_tokens=4000,
                    temperature=0.7
                )
                result = response.choices[0].message.content.strip()
                return markdown_to_html(clean_ai_response(result))
            except Exception as e2:
                logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–∞–∂–µ –Ω–∞ gpt-4o: {e2}")
                return "üìä <b>–ù–æ–≤–æ—Å—Ç–∏ –ê—Ä—Ö–µ–æ–Ω</b>\n\n–°–ª–µ–¥–∏–º –∑–∞ —Ä—ã–Ω–∫–æ–º –ò–ñ–°. –°–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è!"
    
    async def analyze_photo(self, photo_path: str) -> str:
        import base64
            from PIL import Image
            import io
        try:
            with Image.open(photo_path) as img:
                if img.mode != 'RGB': img = img.convert('RGB')
                img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
                buf = io.BytesIO()
                img.save(buf, format='JPEG', quality=85)
                image_data = buf.getvalue()
        except Exception:
            with open(photo_path, "rb") as f: image_data = f.read()
            
        b64 = base64.b64encode(image_data).decode('utf-8')
        prompt = self._get_photo_analysis_prompt()
        
        try:
            response = await asyncio.wait_for(
                self.client.chat.completions.create(
                    model="gpt-5.2",
                    messages=[{
            "role": "user",
            "content": [
                            {"type": "text", "text": f"–ò–ù–°–¢–†–£–ö–¶–ò–Ø: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–æ—Ç–æ –∫–∞–∫ —Ç–µ—Ö–Ω–∞–¥–∑–æ—Ä –ê—Ä—Ö–µ–æ–Ω.\n–ó–ê–î–ê–ù–ò–ï: {prompt}"},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}}
                        ]
                    }],
                    max_completion_tokens=4000
                ),
                timeout=180.0
            )
            return response.choices[0].message.content.strip() or "–°—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –ê—Ä—Ö–µ–æ–Ω."
        except Exception:
            return "–û–±—ä–µ–∫—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –ê—Ä—Ö–µ–æ–Ω."

    async def analyze_multiple_photos(self, photo_paths: List[str]) -> str:
        descs = []
        for i, p in enumerate(photo_paths[:5], 1):
            d = await self.analyze_photo(p)
            descs.append(f"–§–æ—Ç–æ {i}: {d}")
        return "\n\n".join(descs)
    
    async def generate_post_from_sources(self, source_posts: List[Dict[str, str]], topic: Optional[str] = None) -> str:
        if not source_posts: return self._get_fallback_source_post()
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ò–ò, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–≤—è–∑—å —Ç–µ–∫—Å—Ç–∞ –∏ —Å—Å—ã–ª–∫–∏
        context_items = []
        for i, p in enumerate(source_posts[:15], 1): # –ë–µ—Ä–µ–º –¥–æ 15 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã
            text = p.get('text', '')
            source_url = p.get('source', '–ë–µ–∑ —Å—Å—ã–ª–∫–∏')
            if text:
                context_items.append(f"–ù–û–í–û–°–¢–¨ ‚Ññ{i}:\n–¢–ï–ö–°–¢: {text}\n–ò–°–¢–û–ß–ù–ò–ö: {source_url}")
            
        context = "\n\n---\n\n".join(context_items)
        
    sys_prompt = """–¢—ã ‚Äî –≥–æ–ª–æ—Å –∫–æ–º–ø–∞–Ω–∏–∏ –ê—Ä—Ö–µ–æ–Ω. –¢–≤–æ—è –∑–∞–¥–∞—á–∞: –Ω–∞–ø–∏—Å–∞—Ç—å –ø–æ—Å—Ç –¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π. 

–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –°–¢–ò–õ–Æ –ò –¢–ï–†–ú–ò–ù–ê–ú:
1. –ù–ò–ö–ê–ö–û–ì–û –û–§–ò–¶–ò–û–ó–ê: –ü–∏—à–∏ —Ç–∞–∫, –±—É–¥—Ç–æ —Ç—ã —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—à—å —ç—Ç–æ –¥—Ä—É–≥—É –∑–∞ —á–∞—à–∫–æ–π –∫–æ—Ñ–µ. –ò–∑–±–µ–≥–∞–π –æ–±–æ—Ä–æ—Ç–æ–≤ "—Å–æ–æ–±—â–∞–µ—Ç—Å—è", "–æ–±—Å—É–∂–¥–∞–µ—Ç—Å—è", "—Ä—ã–Ω–æ–∫ –≤—Ö–æ–¥–∏—Ç –≤ —Ñ–∞–∑—É".
2. –ó–ê–ë–£–î–¨ –≠–¢–ò –°–õ–û–í–ê: "–∫–ª–∏–µ–Ω—Ç–æ—Ü–µ–Ω—Ç—Ä–∏—á–Ω–æ—Å—Ç—å", "–ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å", "–¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è", "–∏–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è", "—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è", "–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥", "–ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏", "–∏–Ω–¥–µ–∫—Å", "—Ñ–∞–∫—Ç–æ—Ä—ã", "—Å–µ–≥–º–µ–Ω—Ç". 
3. –°–¢–†–û–ì–ò–ï –ó–ê–ú–ï–ù–´: 
   - –í–º–µ—Å—Ç–æ "—Å—Ç—Ä–æ–π–∫–∞ –¥–æ–º–∞" –í–°–ï–ì–î–ê –ø–∏—à–∏ "—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ –¥–æ–º–∞".
   - –ì–ü–ó–£ –∏ –ì—Ä–∞–¥–ø–ª–∞–Ω ‚Äî —ç—Ç–æ –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ, –∏—Å–ø–æ–ª—å–∑—É–π "–ì—Ä–∞–¥–ø–ª–∞–Ω".
4. –ì–†–ê–ú–ú–ê–¢–ò–ö–ê: –ë—É–¥—å –ø—Ä–µ–¥–µ–ª—å–Ω–æ –≤–Ω–∏–º–∞—Ç–µ–ª–µ–Ω –∫ –æ–∫–æ–Ω—á–∞–Ω–∏—è–º. –ü—Ä–∏–º–µ—Ä: "–≤—Ç–æ—Ä—É—é –ª—å–≥–æ—Ç–Ω—É—é –Ω–∞ –¥–æ–º –Ω–µ –¥–∞–¥—É—Ç" (–∞ –Ω–µ "–≤—Ç–æ—Ä–æ–π –ª—å–≥–æ—Ç–Ω—ã–π").
5. –§–ê–ö–¢–´ –û–ë –≠–°–ö–†–û–£: –≠—Å–∫—Ä–æ—É –≤ –ò–ñ–° ‚Äî —ç—Ç–æ –ù–ï –≤—ã–ø–ª–∞—Ç—ã –ø–æ –∞–∫—Ç–∞–º. –≠—Ç–æ –¥–µ–Ω—å–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –ª–µ–∂–∞—Ç –≤ –±–∞–Ω–∫–µ –¥–æ –ø–æ–ª–Ω–æ–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –¥–æ–º–∞. –ë—É–¥—å —Ç–æ—á–µ–Ω –≤ –º–∞—Ç—á–∞—Å—Ç–∏!
6. –ü–ò–®–ò –ü–†–û–°–¢–û: –í–º–µ—Å—Ç–æ "—Å–Ω–∏–∑–∏—Ç –∫–∞—Å—Å–æ–≤—É—é –Ω–∞–≥—Ä—É–∑–∫—É" –Ω–∞–ø–∏—à–∏ "—É —Å—Ç—Ä–æ–∏—Ç–µ–ª–µ–π –±—É–¥–µ—Ç –±–æ–ª—å—à–µ —Å–≤–æ–±–æ–¥–Ω—ã—Ö –¥–µ–Ω–µ–≥ –Ω–∞ –∑–∞–∫—É–ø–∫—É –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤".
7. –¢–´ ‚Äî –≠–ö–°–ü–ï–†–¢-–ü–†–ê–ö–¢–ò–ö: –¢—ã —Å—Ç—Ä–æ–∏—Ç–µ–ª—å –∏–∑ –ö—Ä—ã–º–∞. –î–æ–±–∞–≤–ª—è–π —Å–æ–≤–µ—Ç—ã: "–º—ã –≤ –ê—Ä—Ö–µ–æ–Ω–µ —Å–æ–≤–µ—Ç—É–µ–º...", "–µ—Å–ª–∏ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ —Å—Ç—Ä–æ–∏—Ç—å—Å—è –≤–µ—Å–Ω–æ–π ‚Äî –∑–∞–∫—É–ø–∞–π—Ç–µ –±–ª–æ–∫–∏ —Å–µ–π—á–∞—Å".
8. –¢–ò–ü–û–ì–†–ê–§–ò–ö–ê: –¢–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–∏–µ –¥–µ—Ñ–∏—Å—ã (-). –î–ª–∏–Ω–Ω—ã–µ —Ç–∏—Ä–µ (‚Äî) –∑–∞–ø—Ä–µ—â–µ–Ω—ã.

–°—Ç—Ä—É–∫—Ç—É—Ä–∞:
- –ó–∞–≥–æ–ª–æ–≤–æ–∫ (–±–µ–∑ —Å–ª–æ–≤–∞ "–î–∞–π–¥–∂–µ—Å—Ç")
- 3-4 –∫–æ—Ä–æ—Ç–∫–∏—Ö –±–ª–æ–∫–∞ —Å –ø–æ–ª—å–∑–æ–π
- –ò—Ç–æ–≥: —á—Ç–æ –¥–µ–ª–∞—Ç—å –∫–ª–∏–µ–Ω—Ç—É –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å."""

        topic_str = f"–ü–†–ò–û–†–ò–¢–ï–¢–ù–ê–Ø –¢–ï–ú–ê: {topic}\n" if topic else ""
        user_msg = f"{topic_str}–î–ê–ù–ù–´–ï –ò–ó –ò–°–¢–û–ß–ù–ò–ö–û–í:\n{context}\n\n–ó–ê–î–ê–ù–ò–ï: –ù–∞–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π –ø–æ—Å—Ç. –ï—Å–ª–∏ —Ç–µ–º–∞ —É–∫–∞–∑–∞–Ω–∞ –≤—ã—à–µ ‚Äî —Å—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –Ω–µ–π –Ω–∞ 80%. –û–±—ä—è—Å–Ω—è–π –∫–∞–∂–¥–æ–µ —Å–ª–æ–∂–Ω–æ–µ —Å–ª–æ–≤–æ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—è."
        
        try:
            params = {
                "model": self.model,
                "messages": [{"role": "user", "content": f"–ò–ù–°–¢–†–£–ö–¶–ò–Ø:\n{sys_prompt}\n\n–ó–ê–î–ê–ù–ò–ï:\n{user_msg}"}],
                "max_completion_tokens": 5000
            }
            if self.supports_temperature: params["temperature"] = 0.7
            
            response = await asyncio.wait_for(self.client.chat.completions.create(**params), timeout=180.0)
            res = response.choices[0].message.content.strip()
            
            # –û—á–∏—â–∞–µ–º –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
            cleaned = clean_ai_response(res)
            return markdown_to_html(cleaned)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º: {e}")
            # –§–æ–ª–±—ç–∫ —Å —Å—ã—Ä—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏ –µ—Å–ª–∏ –ò–ò –ø–æ–¥–≤–µ–ª
            links = "\n".join([f"‚Ä¢ {p.get('source')}" for p in source_posts[:5] if p.get('source')])
            return f"üìä <b>–ù–æ–≤–æ—Å—Ç–∏ –ò–ñ–° –ö—Ä—ã–º</b>\n\n–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ —Å —Ä—ã–Ω–∫–∞. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã: –∑–∞–∫–æ–Ω –æ–± –ò–ñ–° –∏ –Ω–æ–≤—ã–µ –∏–ø–æ—Ç–µ—á–Ω—ã–µ —Å—Ç–∞–≤–∫–∏.\n\nüîó <b>–ò—Å—Ç–æ—á–Ω–∏–∫–∏:</b>\n{links}"
    
    async def refine_post(self, original_post: str, edits: str) -> str:
        sys_prompt = "–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –ê—Ä—Ö–µ–æ–Ω. –ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–π —Ç–µ–∫—Å—Ç —Å —É—á–µ—Ç–æ–º –ø—Ä–∞–≤–æ–∫, —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –æ–±—ä–µ–º 1500-2000 —Å–∏–º–≤."
        user_msg = f"–¢–ï–ö–°–¢:\n{original_post}\n\n–ü–†–ê–í–ö–ò:\n{edits}"
        try:
            response = await self.client.chat.completions.create(
                    model=self.model,
                messages=[{"role": "user", "content": f"–ò–ù–°–¢–†–£–ö–¶–ò–Ø:\n{sys_prompt}\n\n–ó–ê–î–ê–ù–ò–ï:\n{user_msg}"}],
                max_completion_tokens=5000
            )
            return markdown_to_html(clean_ai_response(response.choices[0].message.content.strip()))
        except Exception:
            return original_post

    def _get_default_system_prompt(self) -> str:
        return """–¢—ã ‚Äî –≤–µ–¥—É—â–∏–π —ç–∫—Å–ø–µ—Ä—Ç —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏ –ê—Ä—Ö–µ–æ–Ω. –¢–≤–æ–π —Å—Ç–∏–ª—å ‚Äî "—É–º–Ω—ã–π —Å—Ç—Ä–æ–∏—Ç–µ–ª—å".

–ü–†–ê–í–ò–õ–ê –¢–ï–ö–°–¢–ê:
1. –ü–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–æ –∏ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ (1500-2500 —Å–∏–º–≤–æ–ª–æ–≤).
2. –°–¢–†–û–ì–ò–ï –¢–ï–†–ú–ò–ù–´: –í–º–µ—Å—Ç–æ "—Å—Ç—Ä–æ–π–∫–∞ –¥–æ–º–∞" –ø–∏—à–∏ "—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ –¥–æ–º–∞". –ì–ü–ó–£ –∏ –ì—Ä–∞–¥–ø–ª–∞–Ω ‚Äî —ç—Ç–æ –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ.
3. –≠–°–ö–†–û–£: –≠—Ç–æ –¥–µ–Ω—å–≥–∏ –≤ –±–∞–Ω–∫–µ –¥–æ –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–æ–π–∫–∏, –∞ –Ω–µ –ø–æ—ç—Ç–∞–ø–Ω—ã–µ –≤—ã–ø–ª–∞—Ç—ã! –ë—É–¥—å —Ç–æ—á–µ–Ω.
4. –ó–ê–ü–†–ï–©–ï–ù–û –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –∂–∞—Ä–≥–æ–Ω: "–∫–ª–∏–µ–Ω—Ç–æ—Ü–µ–Ω—Ç—Ä–∏—á–Ω–æ—Å—Ç—å", "CX", "SLA", "R&D", "–∫–µ–π—Å", "–æ—Ñ—Ñ–µ—Ä", "–ª–∏–¥".
5. –¢–ò–ü–û–ì–†–ê–§–ò–ö–ê: –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –æ–±—ã—á–Ω—ã–µ –¥–µ—Ñ–∏—Å—ã (-).
6. –ì–†–ê–ú–ú–ê–¢–ò–ö–ê: –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —Å–ª–µ–¥–∏ –∑–∞ —Ä–æ–¥–∞–º–∏ –∏ –ø–∞–¥–µ–∂–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–≤—Ç–æ—Ä—É—é –ª—å–≥–æ—Ç–Ω—É—é")."""

    def _get_photo_analysis_prompt(self) -> str:
        return "–û–ø–∏—à–∏ —ç—Ç–∞–ø —Ä–∞–±–æ—Ç, –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –∫–∞—á–µ—Å—Ç–≤–æ –∏ –¥–µ—Ç–∞–ª–∏ –Ω–∞ —Ñ–æ—Ç–æ –∫–∞–∫ –∏–Ω–∂–µ–Ω–µ—Ä —Ç–µ—Ö–Ω–∞–¥–∑–æ—Ä–∞."
    
    def _get_fallback_source_post(self) -> str:
        return "üèóÔ∏è <b>–ù–æ–≤–æ—Å—Ç–∏ –ê—Ä—Ö–µ–æ–Ω</b>\n\n–°–ª–µ–¥–∏–º –∑–∞ —Ä—ã–Ω–∫–æ–º –ò–ñ–° –ö—Ä—ã–º–∞. –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤ —Å–ª–µ–¥—É—é—â–∏—Ö –≤—ã–ø—É—Å–∫–∞—Ö!"

    async def make_news_standalone(self, text: str) -> str:
        return await self.refine_post(text, "–°–¥–µ–ª–∞–π –Ω–æ–≤–æ—Å—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π, —É–±–µ—Ä–∏ –æ—Ç—Å—ã–ª–∫–∏ –∫ –ø—Ä–æ—à–ª–æ–º—É.")
        
    async def analyze_video(self, video_path: str) -> str:
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —á–µ—Ä–µ–∑ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ (–Ω—É–∂–µ–Ω cv2)
        try:
            import cv2
            cap = cv2.VideoCapture(video_path)
            total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            descs = []
            for i in range(3): # –ë–µ—Ä–µ–º 3 –∫–∞–¥—Ä–∞
                cap.set(cv2.CAP_PROP_POS_FRAMES, (total // 4) * (i + 1))
                ret, frame = cap.read()
                if ret:
                    cv2.imwrite("temp_frame.jpg", frame)
                    d = await self.analyze_photo("temp_frame.jpg")
                    descs.append(d)
            cap.release()
            return "–ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ: " + " ".join(descs)
        except Exception:
            return "–í–∏–¥–µ–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –ê—Ä—Ö–µ–æ–Ω."
